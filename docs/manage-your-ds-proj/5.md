# 五、可靠的模型

Maintaining Performance

在第 [3](3.html) 章中，我们首先遇到了信任方程，其参数包括可信度、可靠性、亲密度和自我导向。虽然你不能和一个模特很亲密，也没有人期望一个模特会为其他人着想，但是一个模特可以是可信和可靠的，也可以是两者兼而有之。在第 4 章[中，我们探讨了如何让一个模型可信，但是模型可靠也很重要。](4.html)

最近，模型需要可靠的概念受到了更多的关注，这至少部分是由于全球金融危机(GFC)的影响，在这场危机中，模型给出的结果很差，原因有很多，包括在模型设计者预期的参数之外使用，以及即使输入数据发生变化也被认为可以继续工作。

全球金融危机(GFC)的余波带来了一种新的对模型使用的怀疑态度，有些是有根据的，有些不是。最近，部分作为对数据科学和大数据炒作的反应，凯茜·奥尼尔 <sup>[1](#Fn1)</sup> 等数据科学领域的作者开始警告人们，疏忽模型的影响会伤害人们，这是他们工作的副作用，甚至是直接结果。这些警告也开始在面向普通读者的文章中出现和重复。<sup>2[2](#Fn2)T7】</sup>

奥尼尔的观点之一是，没有收到反馈的模型可能会以各种方式出错。此外，在许多情况下，在她使用的例子中，经常有多个机会将偏离正确道路的模型设定为正确的，或者做出停止模型的决定。从这个角度来看，这些例子很好地说明了观察和维护模型以确保可靠性的必要性。

不幸的是，用户经常期望模型应该是“设置好就忘记了”，并且没有立即理解维护和重新训练模型的需要。作为一名数据科学家，您的职责是在流程中尽早将他们的期望值设置为正确的水平。

以此为背景来维持用户对模型的信任可能会很困难。在某种程度上，这应该是困难的——有时用户太急于相信来自建模者的好消息，会使建模者很难对他们的模型的性能提出适当的怀疑观点。

前面提到的很多问题都涉及到维护可信度的问题，同时也涉及到与那些急于假设你的模型是可信的用户打交道的问题。信任等式的下一个阶段，可靠性，也开始发挥作用，因为模型不应该自动依赖于无限期地提供相同精度水平的结果。

综上所述，这些因素意味着，尽管需要一些努力来确保模型在长时间内运行到最佳性能，但有时很难说服用户允许您更新它们。这绝对是我的经验，其他作者也注意到，在质量保证、 <sup>[3](#Fn3)</sup> 等活动方面，数据科学作为一门学科落后于其他学科的规范，而这些活动在其他情况下被认为是确保用户和客户获得他们所期望的东西的必要条件。

因此，在这一章中，除了讨论如何使模型保持在最佳状态，我还将讨论如何说服用户这是必要的，而不要让他们认为你的模型在某种程度上是有缺陷的。

在这条路的尽头，存在着一个问题，一个模特应该什么时候退休？这个问题的答案可以追溯到我们的第一章，在那里我们讨论了如何确定你应该解决的问题。风险总是存在的，你的模型的点可能不再存在，因为它要解决的问题不再相关。

## 什么是可靠性

在没有确定可靠性是什么的情况下，很难谈论让你的模型更可靠。在我继续讨论模型的技术定义之前，先考虑一下它对人类的作用可能是有用的。

在“信任等式”的上下文中，可靠性被有效地定义为始终如一且可靠的顾问。因此，他们是这样一种人，他们说到做到，做人们对他们的期望，并且不会以意想不到的消极方式行事。

只要稍加修改，这些属性就可以移植到预测模型中。模型或数据产品还应该做人们期望它做的事情，始终如一地做它该做的事情，而不是以一种意想不到的负面方式表现——实际上，它不应该有负面的副作用。

因此，如果模型继续以与首次开发时相同的级别执行，并且继续做出相同的决策，则可以认为该模型是可靠的，前提是向该模型提供了用户认为是相同的数据-尽管从模型定型集的严格角度来看，这可能不一定是相同的数据。

在这种情况下，我们将模型本身(即由某种机器学习算法产生的一组规则)、提供给它的数据以及它们的共同实现视为一个完整的系统，它们共同构成了模型。

尽管模型或规则是稳定的，并且可能在开发阶段呈现的案例中按预期执行(尽管其他案例可能会出现问题)，但是数据可能会发生变化。此外，实现虽然不会发生相同意义上的变化，但可能会给系统中的错误提供机会。因此，一般来说，这些方面更可能是导致可靠性失效的区域。

随着数据在商业环境中的使用(以及可能的滥用)的扩大，数据质量已经成为一个特别丰富且时尚的讨论话题。有人建议某些标准构成可靠性的组成部分<sup>[4](#Fn4)</sup>——我建议它们更一般地构成应用于模型的可靠性概念。

1.  准确

2.  完整

3.  一致性

4.  完全

5.  可审计性

这一标准的列举，从蔡和朱的文章中，【5】也呈现出了中肯的思想。我建议相关性可以被合并到可靠性中，因为模型用户做出了一个隐含的假设，即模型结果与他们的情况相关——如果结果不是这样，他们将体验到可靠性的损失。

## 当你不检查你的模型时，坏事就会发生

一些最坏的结果可能发生在模型被实现，然后没有考虑到昨天是正确的今天仍然是正确的时候。

这种现象的一些最臭名昭著的例子起源于 GFC。在崩盘期间，之前不相关的变量变得相关，因为一条新闻在下跌时有负面解读。事实上，在极端影响期间，股票价格变得相关的趋势是一个众所周知的问题，然而，在回报更加良性的时期，这个问题被忽视了。

事实上，在 GFC 和其他极端事件期间，由于因变量和自变量之间的关系被破坏，多种行为模型不再正确工作。零售和公司信贷的违约概率模型是这种情况的另一个重要例子。

因此，在标准条件下表现良好的模型在金融危机期间变得非常糟糕是很常见的。如果事件建模团队没有提前开发出碰撞条件下的模型，那么他们将很难及时开发出一个能充分发挥作用的新模型。

这里的教训是，超越金融领域，模型的正确运行在很大程度上依赖于它们的环境与开发它们的环境保持足够的相似。确保模型继续在正确的环境下工作意味着仔细观察环境，以便能够尽早检测到意味着需要新模型的变化，从而避免使用有缺陷的模型。

在 GFC 事件发生后不久，有人说这些事件是“黑天鹅”，也就是说，它们很难在现有模型的框架内预测，因为它们超出了建模者的经验或数据集。这在某种程度上是一种逃避——在 GFC 之前的研究已经表明，在以前的崩盘中，资产相关性发生了实质性的变化，因此，至少研究人员知道模型在崩盘中可能会失效的观点，任何有兴趣找出答案的人都可以得到这一观点。

就像托尔斯泰笔下的不幸家庭一样，模特都有不同程度的问题。有些问题可能很小；其他大的。有时问题实际上意味着模型在某个地方造成了伤害。其他时候，问题只是意味着性能慢慢下降，直到模型比飞镖板好不了多少。

这些问题的共同点是，如果你想在为时已晚之前找到它们，你需要有意识地努力找到它们，你需要一个结构和过程来确保你找到它们。

你是否做对这件事的影响会很大。模型不可信的观点已经开始有了自己的生命，即使宣传数据科学好处的文章不断出现，警告数据科学出错的危险的文章也在激增。

在第 [3](3.html) 章中，我们讨论了数据科学家成为整个数据科学职业的品牌大使的必要性。做到这一点的最实际的方法之一是创建模型，这些模型既能在它们的生命周期中保持它们的性能，又能被信任来完成它们最初的使命，而且这样做不会造成附带的损害。

## 基准输入

一个模型的性能取决于它所输入的数据的质量。数据质量可以有多个维度， <sup>[6](#Fn6)</sup> 这在某种程度上可以由数据的使用方式决定。一些作者已经确定了他们自己的超过 20 个可能维度的列表。然而，六维是特别常用的:<sup>T5 7T7</sup>

*   完全

*   独特性

*   及时

*   有效期

*   准确

*   一致性

可以在几个不同的阶段考虑数据质量的这些方面，例如在建立数据仓库时，或者在开始建模工作时，以便选择最可靠的变量。

然而，当从建模阶段转移到实现阶段时，重要的是避免假设您的初始数据评估足以作为实现的数据质量基准。在建模阶段评估数据质量时，您的注意力将会放在一组不同的标准上，而不是在实现后考虑数据的持续可靠性。因此，如果你没有有意识地决定检查数据是否适合实现，那么你可能会忽略某些方面。

从一开始就知道什么是输入变量的常态是非常重要的。如果一开始没有抽样，你就不会知道你应该期待看到什么，所以你不会知道什么时候事情变得不正常了。

机器学习文本部分忽略探索性数据分析是相对常见的，因为它涉及到确保根据昨天的数据训练的模型仍然适合明天的条件的问题。相反，更常见的是，文本强调探索性数据分析是数据清理和准备的前提，讨论如何处理缺失数据和数据清理的可能方法，从而就准备数据集进行建模的最佳方式提出建议。

虽然这是构建有效模型的必要步骤，但是这一步还应该提供大量的信息。

一旦您将您的模型实现为一个由数据集更新流提供支持的评分引擎，将会有另一组与更新过程的可靠性相关的问题需要解决。即使是最好的维护和编码系统也会有一定程度的错误、遗漏和不连续。如果它们处于足够低的水平，就不会令人担忧。但是，类似于数据集的整体问题，不看就不会发现，不知道的东西会伤害到你。因此，您需要了解数据馈送的特征。

有些人可能认为这是数据工程团队或数据库维护人员的职权范围。然而，虽然我不相信独角兽数据科学家，你也不应该相信，并且你应该在组织允许的情况下尽可能多地帮助维护数据库，但我认为数据治理对于数据科学团队来说太重要了，不能让他们自己置身事外。

因此，对数据治理最佳实践有足够的理解是很重要的，以确保您对该过程有所贡献。类似地，你应该期望领导算法治理，这是一门独立的学科。

通常与模型和数据治理相关的另一个因素是建模偏差，特别是当模型偏差表现为对特定人群的偏差时——种族子群体或社会经济子群体是其中一些更有特色的。如果一个模型被设计来做出影响人们的决策，那么这些影响是一个一直存在的风险，并且在没有人类参与的情况下很难识别，因为人类可以判断模型的影响。

确保您的模型仍然在其预期参数内运行的一般活动直观地要求对那些参数有很强的理解。这种理解既包括数据本身，也包括集中趋势、分布、偏斜度等的统计测量。和数据收集过程。也就是说，数据捕获速率的变化可以指示底层过程已经发生了变化。

例如，如果特定输入变量的提要看到不同的更新模式，或者数据量突然增加或减少，这很可能是数据收集的某个方面发生了变化的迹象，这可能意味着数据的基本质量或含义可能已经发生了变化，即使根据数据的直接采样统计数据并没有立即表现出来。

另一个需要考虑的问题是，如果数据馈送出现临时中断或部分中断，其中一些变量被中断，但其他变量继续更新，会发生什么情况。这是否意味着你的模型的得分输出是不正确的？在什么时候你能识别出有一个中断？

在开始建模之前了解情况的方法也可以用来寻找模型中的偏差。例如，已经多次观察到，犯罪模式的模型反映了执行逮捕的警官的同样的种族或其他偏见，因此，根据黑人在逮捕率中所占比例过高的数据训练的模型很可能导致黑人继续以同样的比例被占比例过高。

了解数据是什么样子，与预期的样子或应该的样子相比较，对于决定数据产生的结果是否可靠是至关重要的。

## 审计模型

我在本章前面提到的可靠模型的属性之一是可审计性。审计只是一个正式的过程，检查您的模型是否按预期执行，是否按预期实现，以及最初是否按预期开发。

因此，审核您实现的机器学习系统是最系统的方法，可以确保您有意识地寻找问题，找到问题，并记录潜在的解决方案。这种认识变得越来越普遍，随着新的压力施加到机器学习系统上，使其更加透明和可靠，正式审计这些系统的想法变得越来越普遍。 <sup>[8](#Fn8)</sup>

虽然这个词经常与会计或税务联系在一起，但事实上，审计可以发生在许多上下文中，对机器学习系统的审计直观上与 it 或类似上下文中发生的审计有更多的共同点。

需要一个正式流程的很大一部分是为了确保审查中没有遗漏任何内容，因为需要审计的系统由几个部分组成，这些部分会产生一些小的差距，从而导致通信丢失。同时，虽然审核是一个定义的过程，其步骤在某种程度上是预先确定的，但是当审核由人工执行时，就有机会更深入地研究任何看起来可疑的领域。

确保覆盖正确区域的预定步骤的组合，以及使用直觉引导搜索困难区域的能力，是处理在模型有偏差时难以找到时间的强有力方法。

执行审计的另一个关键优势是，无论是使用内部审计员还是外部审计员，您都可以使用它来提高模型及其实现的声誉。当你的部分目标是提高用户对你的模型的信任时，这是一个重要的关注点。

为了完成审计，您需要一个框架来进行审计，通常是一个被正式或非正式地认可为标准的框架。数据科学在这个领域没有太多的选择，但是至少有一个作者建议用 CRISP-DM 审计数据科学项目。 <sup>[9](#Fn9)</sup>

在这种情况下，CRISP-DM 流程的优势在于，您可以使用框架中的副标题来引发问题和讨论，讨论您正在审查的数据科学实施在这些要点上的表现。我们已经在第 [2](2.html) 章中看到了 CRISP-DM，但为了强调这些副标题:

*   商业理解

*   数据理解

*   数据准备

*   建模

*   估价

*   部署 <sup>[10](#Fn10)</sup>

这些副标题中的每一个都是审查和验证数据科学实施的自然主题。特别是，尽管有时很容易做出这样的决定:如果一个模型很好地实现了它的准确性度量，那么包含“业务理解”和“部署”作为审计主题应该意味着，一方面，模型确实提供了回答客户业务问题的数据，另一方面，实现的版本确实为客户提供了他们需要的结果。

当然，没有现有的强制性标准甚至是普遍接受的标准意味着如果 CRISP-DM 不符合您的需求，您就不会被它束缚。你可以根据自己的需要改变你想去的深度，如果你认为缺少了什么，你也可以添加到列表中。

当然，你会发现，如果你去一家大公司验证一个模型，他们通常会开发自己的框架，该框架通常涵盖与 CRISP-DM 相似但不完全相同的关注点列表。

## 模型风险评估

来自质量保证的另一个想法是，您可以适应确保您的模型实现预期结果的问题，即在实现之前执行风险评估。这一概念在汽车制造领域尤其普遍，但至少部分归功于六适马，它已经扩展到其他领域。

完成这项工作的正式工具叫做失效模式和影响分析，通常简称为 FMEA。最终，这是一个引导头脑风暴的过程，针对可能出错的事情及其后果，你可以采用适合你情况的正式程度。

通过不同的利益相关者群体和各种不同的提示，可以在不同的彻底程度上进行 FMEA。然而，一些核心活动是通用的，不管是什么场景: <sup>[11](#Fn11)</sup>

*   确定可能的故障模式——流程可能失败的方式

*   确定这些失败的可能结果

*   量化这些结果的严重性

*   根据后果的严重程度，为最重要的故障制定响应计划

*   记录流程的结果

在重视正式流程和文档的环境中，通常通过计算风险优先级来量化严重性。风险优先级数字是通过将问题严重性、发生可能性和检测概率的数字相乘计算出来的。

但是，可以通过小组集体讨论来获得一个整体优先级分数，例如满分，以一种不太费力的方式将这种方法的原理应用到您的情况中。通过采用这种方法，您可以获得自动 FMEA 在问题发生前检测问题的保证，而无需整个过程的官僚作风。这样你就不会让完美成为好的敌人。

这一过程的通常结果是制定一个控制计划，将特定的危险与预防措施相匹配。在制造环境中，这可能意味着在被迫剔除产品或分析原材料之前，如果输出发生变化，则检查机器设置。在机器学习模型的情况下，它更有可能意味着对重要输入变量的数据馈送进行足够的更改，从而触发对数据源的调查，数据源可以是供应商、收集点或传感器。

使用 FMEA 或另一种具有类似理念的工具来寻找过程或实施中的弱点，在制造业的原始环境中已经获得了相当大的成功。如果没有一个系统地寻找这些弱点的过程，制造业中的产品发布将会非常频繁地导致有缺陷的产品被发送给客户，并且制造商经常被客户的缺陷报告所震惊。

在当前环境下，用户可能会因为媒体报道的不良表现或他们自己以前的经历而对数据科学模型持怀疑态度，采用这些相同的工具有助于确保您的最终实施提供积极的体验，使用户再次信任数据科学。

## 模型维护

随着时间的推移，随着关系的改变，任何统计或机器学习模型都会经历性能损失。有时这种情况发生得非常突然，就像 GFC 危机期间许多信用违约模型发生的情况一样。其他时候，退化发生在一个较长的时期，并且几乎可以由观察趋势的人来预测。

是什么导致了退化？首先，不管你有多小心，在某种程度上，你的模型符合噪音或潜在因素，也就是说，它是错误的，开始，你的一些准确性是由于随机的机会。

从这两个例子中可以直观地看出，依赖于人类行为的模型可能特别容易退化，而在某种意义上与物理过程更密切相关的模型可能具有一些额外的稳定性。接下来，了解这对于您的模型的风险有多大以及在什么时间范围内将成为您的主题专家的关键盟友，并且在大多数情况下，将制定模型审查和再培训的定期计划。

同时，您可能希望使用数据告诉您的信息，因此您需要一些方法来确定新到达的输入数据是否已经更改。对于快速变化的环境尤其如此。

在数据点具有高度独立性的输入变量的情况下，统计过程控制(SPC)中使用的控制图可用于检测过程的变化。

有很多关于这些图表的使用指南，包括印刷版和网络版，它们已经被成功使用了很多年。它们的共同之处在于，来自一个过程的测量值被顺序地绘制在一个图表上，在平均值(或其他适当的过程平均值)处有一条中心线，上下线代表通常的过程范围。因此，很容易确定过程何时改变了其范围或其平均结果。

但是，特别是对于属性或分类数据，为相对较小的数据开发的方法在用于大量数据时会产生有问题的结果。

在设置连续数据的采样方案时仍需小心谨慎-请注意，没有必要使用每天收集的完整数据来检查输入变量的过程是否保持了模型实施时的特征，只要它足够大以具有代表性即可。

### 系统数据监控

只要您对自己环境中的正常和异常数据有一个清晰的理解，数据监控就是一个提供大量自动化机会的领域，至少有明确的系统化方法。

一种直观的方法是调整质量控制监控的原则，其中使用统计图表来检测收集的一系列数据何时发生变化，以此提醒负责人检查条件并可能采取行动。

控制图起源于制造业，在制造业中，测量产品某一方面的操作员可以快速评估潜在的过程是否已经改变。控制图有多种格式，以适应它们所应用的数据类型，但最常见的两种形式是 x-bar 和 R (x-bar 表示平均值，R 表示范围)和 c-chart(用于可计数事件)。

SPC 控制图是在一组预先确定的规则的上下文中进行解释的，这些规则确定了流程何时发生了变化，包括看到七个或更多连续点高于平均值，或者七个或更多连续点上升或下降，尽管在使用哪些规则上可能会有少量的变化。 <sup>[12](#Fn12)</sup>

创建和解释质量控制图的原则适用于各种环境，数据质量工作者越来越认识到如何使用它们来检测数据质量可能意外受损的情况。他们也相对较好地适应了自动化，尽管在自动化规则提醒他们注意某个问题后，阅读图表的人是决定实际发生了什么的最佳人选。

现在已经提出或修改了特定的图表用于数据流。 <sup>[14](#Fn14)</sup> 研究人员注意到，数据流的统计属性并不总是遵循一些基本类型的统计控制图所假设的正态分布，尤其是在试图衡量我们之前首次列出的数据质量的六个维度时。

请记住，在大多数情况下，使用控制图更常见的方法是启动一项调查，即使是非常短暂的调查，以决定最佳的行动方案，而不是强制进行自动调整。这是有意义的，因为这些工具是用来识别已经发生的不寻常的事情的，但是对于识别不寻常的事情是什么却非常有限或者甚至没有能力。

已经开发了特定的控制图来识别过程何时按预期停止运行——累积和(通常缩写为“cusum”)图是一个突出的例子。

了解流程何时停止正常运行是发现发生了什么的重要一步——如果您有外部数据提供者，提供发生变化的日期意味着他们更有可能提出可能的变化。同样，当您捕获自己的数据时，能够追溯到特定日期将非常有助于您确定变化的原因。

同时，在理想的情况下，您至少应该在计划阶段就识别出一些可能的干扰原因，比如通过 FMEA 或控制计划活动。如果你有，你将在哪里寻找原因上有一个领先的开始，并且可能有一个默认的纠正措施要采取(尽管你不应该期望在早期阶段已经预料到所有可能发生的事情)。

审核您的机器学习系统、评估不良结果的风险以及监控其输入和输出的过程是您可以采取的最佳措施，以确保您的项目交付其预期结果。不执行这些操作的风险类似于制造一辆在点火时无法启动的汽车的风险，或者更糟的是，虽然可以启动，但无法正确转向或刹车。

## 摘要

为了让用户信任你创建的模型，它们需要既可信又可靠。这一章关注于保持模型的可靠性。虽然可靠性有许多方面，但其中有一条共同的主线，即如果你不寻找问题，你就有可能在你的用户发现问题之前发现不了问题，因此你已经失去了用户的信任。

目前，由于越来越多的人意识到模型在简单的语言意义上可能存在偏见，因此模型在某些方面存在问题受到了额外的关注——它们可能歧视少数群体，或者以其他方式使被建模人群中的子群体处于不公平的不利地位。

从广义上来说，检测问题的一种直观方法是在模型生命周期的关键里程碑处对其进行审计。直观的例子包括实施前和实施一周年。

通过进行审计，您能够超越一些纯粹的技术属性(尽管它们通常会被包括在内),看到模型是否实现了它的业务目标，实现它的基础设施是否确保它保持了预期的性能，以及是否有意想不到的后果。

您还可以通过执行预实施风险分析(例如通过 FMEA)来防范潜在的副作用和意外结果。这是一种用于质量保证的常用工具，它试图在问题发生之前预测问题，并采取措施来防止问题或减轻影响。

对前面提到的两个想法的补充是监视传入的数据源和您的模型的结果。为了确保模型达到预期的精度，在开发和验证模型时，输入数据和结果的分布应该接近它们的分布。此外，传入数据速率的峰值或下降可能表明基础数据本身发生了变化，这可能会损害模型的结果。

统计过程控制图是专门为监控过程而设计的，目的是检测过程何时停止“正常”或“预期”通过建立流程的常规统计范围，他们意味着对您的流程进行快速直观检查可以确定您的流程是否正常运行，并有助于确定它何时停止正常运行。

这些将质量保证思想应用到数据科学模型中的措施有望提高您的系统的预期表现。它们将允许您和您的用户确信您所做的声明将由模型来实现。

在第 [6](6.html) 章中，我们将研究如何以最佳优势传达这些主张。

## 可靠模型清单

*   在实施之前，您是否进行了风险评估？

*   您是否设置了对输入数据质量及其分布的监控，以及对输出数据的监控？

*   如果数据超出您的限制，您是否制定了行动或调查计划？

*   您知道数据质量的哪些方面与您的实施相关吗？你如何发现他们的行为是否发生了变化？

*   你是否评估过你的模型的结果，并试图发现你组织模型的方式所带来的意想不到的结果？

*   您是否与模型用户就模型的检查和再培训频率达成一致？该协议是如何记录的？

<aside class="FootnoteSection" epub:type="footnotes">Footnotes [1](#Fn1_source)

凯茜·奥尼尔，*数学毁灭的武器*(纽约:皇冠出版社，2016)。

  [2](#Fn2_source)

戴夫·格什高恩(Dave Gershgorn)，“科技公司刚刚意识到他们的人工智能存在一个大问题”，*石英，*2018 年 6 月 30 日， [qz。com/1316050/tech-companies-just-wake-to-a-big-problem with-they-ai/](http://qz.com/1316050/tech-companies-just-woke-up-to-a-big-problem-with-their-ai)。

  [3](#Fn3_source)

Irv Lustig，“将 QA 带入数据科学”，*软件测试新闻，*2018 年 10 月 11 日， [`www.softwaretestingnews.co.uk/bringing-qa-to-data-science-2/`](http://www.softwaretestingnews.co.uk/bringing-qa-to-data-science-2/) 。

  [4](#Fn4_source)

和朱，“大数据时代的数据质量与数据质量评估的挑战”，*《数据科学杂志》*，14 期，第 2 页，2015 年 5 月 22 日，DOI: [`https://doi.org/10.5334/dsj-2015-002`](https://doi.org/10.5334/dsj-2015-002) 。

  [5](#Fn5_source)

同上。

  [6](#Fn6_source)

Fatimah Sidi 等，“数据质量:数据质量维度的调查”，2012，*信息检索与知识管理国际会议，*DOI:10.1109/infrkm . 2012.6204995。

  [7](#Fn7_source)

*数据质量评估的六个主要维度*，英国 DAMA，2013 年 10 月， [`www.damauk.org/community.php?sid=7997d2df1befd7e241a39169a2c95780&communityid=1000054`](http://www.damauk.org/community.php%253Fsid%253D7997d2df1befd7e241a39169a2c95780%2526communityid%253D1000054) 。

  [8](#Fn8_source)

詹姆斯·古斯卡(James Guszcza)、伊亚德·拉赫万(Iyad Rahwan)、威尔·圣经(Will Bible)、曼努埃尔·切布里安(Manuel Williams)、维克·卡蒂亚尔(Vic Katyal)，《为什么我们需要审计算法》，*《哈佛商业评论》*，2018 年 11 月 28 日， [`https://hbr.org/2018/11/why-we-need-to-audit-algorithms`](https://hbr.org/2018/11/why-we-need-to-audit-algorithms) 。

  [9](#Fn9_source)

Andrew Clark，《机器学习审计—CRISP-DM 框架》， *ISACA Journal* ，2018 年第 1 卷， [`www.isaca.org/Journal/archives/2018/Volume-1/Pages/the-machine-learning-audit-crisp-dm-framework.aspx`](http://www.isaca.org/Journal/archives/2018/Volume-1/Pages/the-machine-learning-audit-crisp-dm-framework.aspx) 。

  [10](#Fn10_source)

皮特·查普曼、朱利安·柯林顿、兰迪·克伯、托马斯·卡巴扎、托马斯·雷纳茨、科林·希勒、吕迪格·沃思、*克里斯普-DM 1.0* 、 [`www.the-modeling-agency.com/crisp-dm.pdf`](http://www.the-modeling-agency.com/crisp-dm.pdf) 。

  [11](#Fn11_source)

Roger W. Berger，Donald W. Benbow，Ahmad K. Elshennay 和 Walker HF，*《注册质量工程师手册》*(密尔沃基，WI: ASQ 质量出版社，2002 年)。

  [12](#Fn12_source)

道格拉斯·c·蒙哥马利，*《统计质量控制导论》*(纽约:威利，1997)。

  [13](#Fn13_source)

拉杰什.朱古勒。*与高质量数据竞争*(纽约:威利，2016)。

  [14](#Fn14_source)

余，，吴宗杰，郑福基，“使用两步控制方案监控数据流的数据质量”，*《IISE 学报》，【2018 年 10 月，DOI:10.1080/24725854。40364.86668666666*

 </aside>