# 四、超级计算简介

在上一章中，我们学习了 Python 编程语言的历史和哲学。

在这短短的一章中，我们将学习超级计算的概念和历史。

## 超级计算机的概念

超级计算机是一种具有强大处理能力的特殊计算机。这是超级计算机这个术语最简单的定义。超级计算机区别于其他类型计算机的关键特征是它们巨大的处理能力。

超级计算机用于计算密集型应用。这些大多是科学应用。以下是几个例子:

*   天气预报
*   气候研究
*   分子建模
*   物理模拟
*   量子力学
*   石油和天然气勘探

## 超级计算机简史

控制数据公司(CDC)是超级计算机的摇篮。在这里，1964 年，西摩·克雷建造了 CDC 6600。它被称为第一台超级计算机，因为它的性能超过了同时代的所有其他计算机。它的处理速度约为 10 兆赫。1968 年，西摩·克雷建造了 CDC 7600。它的处理速度是 35 兆赫。同样，它是最快的计算机，在计算能力方面超过了所有其他计算机。

这就是超级计算机的起源。最终，克雷离开了 CDC，并成立了自己的公司来设计和开发超级计算机。克雷创造了历史上一些最成功的超级计算机，即克雷 1、克雷 X-MP、克雷 2 和克雷 Y-MP。20 世纪 90 年代见证了大规模并行超级计算机的时代，数千个处理器以各种配置相互连接。一个显著的例子是 Intel Paragon，它可能有许多 Intel i860 处理器。

超级计算机的速度是以每秒浮点运算(FLOPS)而不是 MIPS(每秒百万条指令)来衡量的。英特尔 ASCI Red 是第一台 TFLOPS (Tera FLOPS)超级计算机。2008 年，IBM Roadrunner 成为第一台速度为 PFLOPS (Peta FLOPS)的超级计算机。

超级计算领域的下一个突破将是以 Exa-FLOPS 计算处理速度的 Exascale 超级计算机。

我在这里不提供前 10 名超级计算机或最快的超级计算机的列表。这是因为名单每年都在变化。此外，超级计算机基于各种参数进行排名，因此基于不同参数的不同来源的排名不会相同。

## 串

在设计大规模并行计算系统时，通常遵循两种方法。第一种是让分布在广阔地理区域的成千上万台计算机通过互联网来解决一个特定的问题。这在像互联网这样的广域网上工作得很好。这些类型的系统被称为分布式系统。另一种方法是将数千个处理节点彼此靠近放置。这节省了大量通信时间，并且大部分处理能力用于解决计算量巨大的问题。这种方法被称为聚类。所有的超级计算机都属于这一类。

计算机集群被定义为一组松散耦合或紧密耦合在一起工作的计算机。群集中的计算机称为节点。集群中的所有节点执行完全相同类型的任务。

我们将要开发的微型超级计算机将是一个 pi 集群。所有的超级计算机都是集群，但不是所有的集群都是超级计算机。正如我们在超级计算机的定义中所了解到的，超级计算机拥有巨大的处理能力。这就是为什么每个集群都没有资格被称为超级计算机。我们将在这里构建的集群不是一台超级计算机，因为它在处理能力方面比现实世界的超级计算机逊色，但它的工作原理与现实世界的超级计算机相同。因此我们称它为小型超级计算机。自从引入大规模并行系统以来，大规模集群和功能较弱的计算机之间的界限开始变得模糊。今天，很少有自制的集群像 20 世纪 80 年代的超级计算机那样强大。根据其配置，商品集群分为以下两类。

### 异质集群

当集群的所有节点不具有完全相同的硬件配置时，该集群被称为异构集群。在制作我的集群时，我使用了两个单位的 Pi B+，一个单位的 Pi 2，一个单位的 Pi 3，所以我的集群是一个异构集群。

### 贝奥武夫星团

与异构集群不同，Beowulf 集群中的所有节点具有完全相同的配置。我们可以用商品级硬件和 SBC(如 Raspberry Pi)制作同构集群和 Beowulf 集群。几乎所有集群都使用 Linux 的某个发行版作为其节点的操作系统。

根据您附近 Pi 模型的可用性，您可以创建异构集群或 Beowulf 集群。

## 并行和并发

让我们探讨一下超级计算领域的几个重要术语。

### 平行

并行性意味着计算任务是并行执行的。这意味着这些任务是同时执行的。并行通常用于计算问题非常大的情况。大问题通常被分成更小的子问题，然后由计算机并行解决。随着多核处理器的引入，硬件本身支持并行程序的执行。运行并行程序的另一种方式是通过使用多台不同的计算机来创建并行系统。Parallel 是 serial 的反义词，意思是一个接一个地串联。并行性与另一个术语“并发性”密切相关。

让我用简单的话解释一下排比。假设有两项工作要完成，有两个人可以承担这两项工作。两个人都被分配了一项工作，他们开始各自独立地工作。这就是所谓的并行。

### 并发

并发意味着许多计算任务同时进行。任务不必同时进行。在并行中，所有的任务同时执行。在并发中，它们不需要。在并发系统中，一个计算可以在不等待所有其他计算完成的情况下进行，并且可以同时进行多个计算。并发性的最好例子是操作系统中的进程调度。

让我用简单的语言解释一下并发性。假设要完成两项工作，而只有一个人可以完成所有的工作。这个人决定从第一份工作开始。他做了 30%，然后转到第二份工作。他完成了第二份工作的 40%,并切换回第一份工作。这种类型的切换会发生多次。我们可以说这两项工作都在进行中。虽然这些工作不是同时完成的，但它们正在朝着完成的方向前进。最后，两个工作都完成了。并发是顺序的反义词。

### 并行编程

所有集群和超级计算机都使用并行性来将计算量巨大的任务分解成较小的块，然后收集结果作为最终输出。支持这种类型操作的编程范例被称为并行编程。消息传递接口(MPI)是工业界和学术界最常用的并行编程标准之一。我们将在下一章研究如何在 Python 3 的 Pi 上安装它。

## 结论

在这短短的一章中，我们学习了一些与超级计算相关的重要概念，我们还学习了超级计算机的历史。

在下一章中，我们将学习如何建立一个树莓派集群的节点。