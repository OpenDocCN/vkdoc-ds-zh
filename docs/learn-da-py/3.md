# 三、准备数据是成功的一半

数据分析的第二步是清理数据。为分析工具准备数据可能是一项艰巨的任务。Python 和它的库试图让它尽可能简单。

只需几行代码，您就可以为分析准备好数据。你将能够

*   清理数据；
*   创建新变量；和
*   组织数据。

## 清理数据

为了对大多数分析任务有用，数据必须是干净的。这意味着它应该是一致的、相关的和标准化的。在本章中，您将学习如何

*   去除异常值；
*   去除不合适的价值观；
*   删除重复项；
*   去掉标点符号；
*   删除空白；
*   标准化日期；和
*   规范文本。

### 计算和移除异常值

假设你正在收集和你一起上高中的人的数据。如果你和比尔·盖茨是高中同学呢？现在，即使身家第二高的人只值 150 万美元，你们全班的平均水平也是被排名第一的亿万富翁推高的。通过查找异常值，您可以移除过高或过低的值，这些值会扭曲数据的整体视图。

我们介绍了两种检测异常值的主要方法:

1.  标准差:如果数据是正态分布的，那么 95%的数据在平均值的 1.96 个标准差以内。因此，我们可以删除高于或低于该范围的值。
2.  四分位数范围(IQR):IQR 是 25%分位数和 75%分位数之间的差值。任何低于 Q1 - 1.5 倍 IQR 或大于 Q3 + 1.5 倍 IQR 的值都被视为异常值并被移除。

让我们看看这些是什么样子的(清单 [3-1](#Par19) 和 [3-2](#Par24) )。

*   第 6 行:这里我们计算的上限等于标准差加上平均值的 1.96 倍。
*   第 7 行:这里我们计算的下限等于平均值减去标准差的 1.96 倍。
*   第 9 行:这里我们删除等级高于`toprange`的行。
*   第 11 行:这里我们删除等级低于`botrange`的行。

```py
import pandas as pd
Location = "datasets/gradedata.csv"
df = pd.read_csv(Location)
meangrade = df['grade'].mean()
stdgrade = df['grade'].std()
toprange = meangrade + stdgrade * 1.96
botrange = meangrade - stdgrade * 1.96
copydf = df
copydf = copydf.drop(copydf[copydf['grade']
        > toprange].index)
copydf = copydf.drop(copydf[copydf['grade']
        < botrange].index)
copydf
Listing 3-1Method 1: Standard Deviation 

```

*   第 9 行:这里我们计算上限=第三个四分位数+1.5 * IQR。
*   第 10 行:这里我们计算下边界=第一个四分位数-1.5 * IQR。
*   第 13 行:这里我们删除等级高于`toprange`的行。
*   第 14 行:这里我们删除等级低于`botrange`的行。

```py
import pandas as pd
Location = "datasets/gradedata.csv"
df = pd.read_csv(Location)
q1 = df['grade'].quantile(.25)
q3 = df['grade'].quantile(.75)
iqr = q3-q1
toprange = q3 + iqr * 1.5
botrange = q1 - iqr * 1.5
copydf = df
copydf = copydf.drop(copydf[copydf['grade']
        > toprange].index)
copydf = copydf.drop(copydf[copydf['grade']
        < botrange].index)
copydf
Listing 3-2Method 2: Interquartile Range 

```

#### 轮到你了

加载数据集`datasets/outlierdata.csv`。你能去除异常值吗？两种方法都试试。

### Pandas 数据帧中的缺失数据

处理大型数据集最令人烦恼的事情之一就是寻找丢失的数据。这使得计算大多数聚合统计数据或生成数据透视表变得不可能或不可预测。如果您在一个 50 行的数据集中寻找缺失的数据点，这是相当容易的。然而，如果你试图在一个 500，000 行的数据集中找到一个缺失的数据点，那就困难多了。

Python 的`pandas`库具有帮助你查找、删除或更改缺失数据的功能(清单 [3-3](#Par32) )。

```py
import pandas as pd
df = pd.read_csv("datasets/gradedatamissing.csv")
df.head()
Listing 3-3Creating Dataframe with Missing Data

```

前面的代码加载了一个合法的数据集，该数据集包含丢失数据的行。我们可以使用得到的数据帧来练习处理缺失数据。

要删除所有缺少(NaN)数据的行，使用清单 [3-4](#Par35) 中所示的代码。

```py
df_no_missing = df.dropna()
df_no_missing
Listing 3-4Drop Rows with Missing Data

```

要添加用空值填充的列，请使用清单 [3-5](#Par37) 中的代码。

```py
import numpy as np
df['newcol'] = np.nan
df.head()
Listing 3-5Add a Column with Empty Values

```

要删除只包含空值的任何列，请参见清单 [3-6](#Par39) 。

```py
df.dropna(axis=1, how="all")
Listing 3-6Drop Completely Empty Columns

```

要用零替换所有空值，请参见清单 [3-7](#Par41) 。

```py
df.fillna(0)
Listing 3-7Replace Empty Cells with 0

```

用等级的平均值填写缺失的等级，见清单 [3-8](#Par43) 。

```py
df["grade"].fillna(df["grade"].mean(), inplace=True)
Listing 3-8Replace Empty Cells with Average of Column

```

注意，`inplace=True`表示更改立即保存到数据帧。

要用每个性别的成绩平均值填写缺失的成绩，请参见清单 [3-9](#Par46) 。

```py
df["grade"].fillna(df.groupby("gender")
     ["grade"].transform("mean"), inplace=True)
Listing 3-9It's Complicated

```

我们也可以选择一些行，但忽略那些缺少数据点的行。要选择`df`中年龄不是 NaN 且性别不是 NaN 的行，请参见清单 [3-10](#Par48) 。

```py
df[df['age'].notnull() & df['gender'].notnull()]
Listing 3-10Selecting Rows with No Missing Age or Gender

```

#### 轮到你了

加载数据集`datasets/missinggrade.csv`。如果你选择接受，你的任务就是删除缺失等级的行，并用该性别的平均值替换缺失的锻炼小时数。

### 过滤不适当的值

有时，如果您正在处理不是您自己收集的数据，您需要担心这些数据是否准确。见鬼，有时你需要担心这一点，即使是你自己收集的！检查每一个数据点的准确性可能很困难，但检查数据是否合适却很容易。

Python 的`pandas`库能够过滤掉不好的值(参见清单 [3-11](#Par52) )。

```py
import pandas as pd

names = ['Bob','Jessica','Mary','John','Mel']
grades = [76,-2,77,78,101]

GradeList = zip(names,grades)
df = pd.DataFrame(data = GradeList,
    columns=['Names', 'Grades'])
df

Listing 3-11Creating Dataset

```

要删除等级过高的所有行，请参见清单 [3-12](#Par54) 。

```py
df.loc[df['Grades'] <= 100]
Listing 3-12Filtering Out Impossible Grades

```

要将越界值更改为最大或最小允许值，我们可以使用清单 [3-13](#Par56) 中的代码。

```py
df.loc[(df['Grades'] >= 100,'Grades')] = 100
Listing 3-13Changing Impossible Grades

```

#### 轮到你了

使用本部分的数据集，您能否用零级替换所有的零下级？

### 查找重复行

如果你在使用别人的数据，你需要担心的另一件事是是否有任何数据是重复的。(相同的数据是被报告两次，还是被记录两次，还是仅仅被复制和粘贴？)见鬼，有时你需要担心这一点，即使你确实自己收集了它！检查每个数据点的准确性可能很困难，但检查数据是否重复却很容易。

Python 的`pandas`库不仅有查找重复行的功能，还有查找唯一行的功能(清单 [3-14](#Par60) )。

```py
import pandas as pd
names = ['Jan','John','Bob','Jan','Mary','Jon','Mel','Mel']
grades = [95,78,76,95,77,78,99,100]
GradeList = zip(names,grades)
df = pd.DataFrame(data = GradeList,
        columns=['Names', 'Grades'])
df
Listing 3-14Creating Dataset with Duplicates

```

为了指出重复的行，我们可以简单地运行清单 [3-15](#Par62) 中的代码。

```py
df.duplicated()
Listing 3-15Displaying Only Duplicates in the Dataframe

```

为了显示没有重复的数据集，我们可以运行清单 [3-16](#Par64) 中的代码。

```py
df.drop_duplicates()
Listing 3-16Displaying Dataset without Duplicates

```

您可能会问，“如果整行都没有重复，但我仍然知道它是重复的，那该怎么办？”如果有人做你的调查或重新参加考试，就会发生这种情况，所以名称相同，但观察结果不同。在这种情况下，我们知道重复的名称意味着重复的条目，我们可以使用清单 [3-17](#Par66) 中的代码。

```py
df.drop_duplicates(['Names'], keep="last")
Listing 3-17Drop Rows with Duplicate Names, Keeping the Last Observation

```

#### 轮到你了

加载数据集`datasets/dupedata.csv`。我们认为地址相同的人是重复的。你能在保留第一行的同时删除重复的行吗？

### 从列内容中删除标点符号

无论是电话号码还是地址，您经常会在数据中发现不需要的标点符号。让我们加载一些数据来看看如何解决这个问题(清单 [3-18](#Par69) )。

```py
import pandas as pd
Location = "datasets/gradedata.csv"
## To add headers as we load the data...
df = pd.read_csv(Location)
df.head()
Listing 3-18Loading Dataframe with Data from CSV File

```

为了删除不需要的标点符号，我们创建了一个函数来返回所有不属于标点符号的字符，然后我们将这个函数应用到我们的数据帧中(清单 [3-19](#Par71) )。

```py
import string
exclude = set(string.punctuation)
def remove_punctuation(x):
    try:
        x = ''.join(ch for ch in x if ch not in exclude)
    except:
        pass
    return x
df.address = df.address.apply(remove_punctuation)

df

Listing 3-19Stripping Punctuation from the Address Column

```

### 从列内容中删除空白

```py
import pandas as pd
Location = "datasets/gradedata.csv"
## To add headers as we load the data...
df = pd.read_csv(Location)
df.head()
Listing 3-20Loading Dataframe with Data from CSV File

```

为了消除空白，我们创建了一个函数，它返回所有非标点符号的字符，然后我们将这个函数应用于我们的数据帧(清单 [3-21](#Par74) )。

```py
def remove_whitespace(x):
    try:
        x = ''.join(x.split())
    except:
        pass
    return x
df.address = df.address.apply(remove_whitespace)

df

Listing 3-21Stripping Whitespace from the Address Column

```

### 标准化日期

整合不同来源的数据的一个问题是，不同的人和不同的系统可能会以不同的方式记录日期。也许他们用 1980 年 3 月 1 日，或者他们用 1980 年 3 月 1 日，甚至他们用 1980 年 1 月 3 日。即使它们都指向 1980 年 1 月 3 日，如果您在同一列中的不同格式之间来回切换，分析工具可能不会将它们都识别为日期(清单 [3-22](#Par76) )。

```py
import pandas as pd
names = ['Bob','Jessica','Mary','John','Mel']
grades = [76,95,77,78,99]
bsdegrees = [1,1,0,0,1]
msdegrees = [2,1,0,0,0]
phddegrees = [0,1,0,0,0]
bdates = ['1/1/1945','10/21/76','3/3/90',
        '04/30/1901','1963-09-01']
GradeList = zip(names,grades,bsdegrees,msdegrees,
        phddegrees,bdates)
columns=['Names','Grades','BS','MS','PhD',"bdates"]
df = pd.DataFrame(data = GradeList, columns=columns)
df
Listing 3-22Creating Dataframe with Different Date Formats

```

清单 [3-23](#Par78) 显示了一个将日期标准化为单一格式的函数。

```py
from time import strftime
from datetime import datetime
def standardize_date(thedate):
    formatted_date = ""
    thedate = str(thedate)
    if not thedate or thedate.lower() == "missing"
                or thedate == "nan":
        formatted_date = "MISSING"
    if the_date.lower().find('x') != -1:
        formatted_date = "Incomplete"
    if the_date[0:2] == "00":
        formatted_date = thedate.replace("00", "19")
    try:
        formatted_date = str(datetime.strptime(    
        thedate,'%m/%d/%y')
.strftime('%m/%d/%y'))
    except:
        pass
    try:
        formatted_date = str(datetime.strptime(
thedate, '%m/%d/%Y')
.strftime('%m/%d/%y'))
    except:
        pass
    try:
        if int(the_date[0:4]) < 1900:
            formatted_date = "Incomplete"
        else:
            formatted_date = str(datetime.strptime(
            thedate, '%Y-%m-%d')
.strftime('%m/%d/%y'))
    except:
        pass
    return formatted_date
Listing 3-23Function to Standardize Dates

```

现在我们有了这个函数，我们可以将它应用到我们的数据帧上的`birthdates`列(清单 [3-24](#Par80) )。

```py
df.bdates = df.bdates.apply(standardize_date)
df
Listing 3-24Applying Date Standardization to Birthdate Column

```

### 标准化文本，如 SSN、电话号码和邮政编码

整合来自不同来源的数据的一个问题是，不同的人和不同的系统可能会以不同的方式记录某些数据，如社会保险号、电话号码和邮政编码。也许他们在那些数字中使用连字符，也许他们没有。本节快速介绍了如何标准化这些类型的数据的存储方式(参见清单 [3-25](#Par82) )。

```py
import pandas as pd
names = ['Bob','Jessica','Mary','John','Mel']
grades = [76,95,77,78,99]
bsdegrees = [1,1,0,0,1]
msdegrees = [2,1,0,0,0]
phddegrees = [0,1,0,0,0]
ssns = ['867-53-0909','333-22-4444','123-12-1234',
        '777-93-9311','123-12-1423']
GradeList = zip(names,grades,bsdegrees,msdegrees,
        phddegrees,ssns)
columns=['Names','Grades','BS','MS','PhD',"ssn"]
df = pd.DataFrame(data = GradeList, columns=columns)
df
Listing 3-25Creating Dataframe with SSNs

```

清单 [3-26](#Par84) 中的代码创建了一个标准化 SSNs 的函数，并将其应用于我们的`ssn`列。

```py
def right(s, amount):
    return s[-amount]
def standardize_ssn(ssn):
    try:
        ssn = ssn.replace("-","")
        ssn = "".join(ssn.split())
        if len(ssn)<9 and ssn != 'Missing':
            ssn="000000000" + ssn
            ssn=right(ssn,9)
    except:
        pass
    return ssn
df.ssn = df.ssn.apply(standardize_ssn)
df
Listing 3-26Remove Hyphens from SSNs and Add Leading Zeros if Necessary

```

## 创建新变量

一旦数据没有错误，您需要设置直接回答您的问题的变量。这是一个罕见的数据集，其中你需要回答的每个问题都直接由一个变量来解决。因此，您可能需要对变量进行大量的重新编码和计算，以准确获得您需要的数据集。

例子包括如下:

*   创建 bin(比如将数字等级转换为字母等级，或者将日期范围转换为 Q1、Q2 等。)
*   创建对另一列中的值进行排序的列
*   创建一个列来指示另一个值已达到阈值(通过或失败、院长名单等)。)
*   将字符串类别转换为数字(用于回归或相关)

### 宁滨数据

有时，您会有需要分组到箱中的离散数据。(想想:把数字成绩转换成字母成绩。)在这节课中，我们将学习宁滨(列表 [3-27](#Par92) )。

```py
import pandas as pd
Location = "datasets/gradedata.csv"
df = pd.read_csv(Location)
df.head()
Listing 3-27Loading the Dataset from CSV

```

既然数据已经加载，我们需要定义 bin 和组名(清单 [3-28](#Par94) )。

```py
# Create the bin dividers
bins = [0, 60, 70, 80, 90, 100]
# Create names for the four groups
group_names = ['F', 'D', 'C', 'B', 'A']
Listing 3-28Define Bins as 0 to 60, 60 to 70, 70 to 80, 80 to 90, 90 to 100

```

请注意，bin 值比`group_names`多一个。这是因为每个箱需要有一个顶部和底部限制。

```py
df['lettergrade'] = pd.cut(df['grade'], bins,
        labels=group_names)
df
Listing 3-29Cut Grades

```

清单 [3-29](#Par96) 基于`bins`列表对列`grade`进行分类，并使用`group_names`列表对值进行标记。

如果我们想计算每个类别的观察值，我们也可以这样做(清单 [3-30](#Par99) )。

```py
pd.value_counts(df['lettergrade'])
Listing 3-30Count Number of Observations

```

#### 轮到你了

从该部分重新创建数据帧，并创建一个列，将该行分类为通过或失败。这是一个硕士项目，要求学生达到 80 分或以上才能通过。

### 将函数应用于组、箱和列

我使用 Python 分析数据的首要原因是处理大于一百万行的数据集。第二个原因是对我的数据应用函数很容易。

为了看到这一点，首先我们需要加载一些数据(清单 [3-31](#Par103) )。

```py
import pandas as pd
Location = "datasets/gradedata.csv"
df = pd.read_csv(Location)
df.head()
Listing 3-31Loading a Dataframe

from a CSV File

```

然后，我们用宁滨把数据分成字母等级(列表 [3-32](#Par105) )。

```py
# Create the bin dividers
bins = [0, 60, 70, 80, 90, 100]
# Create names for the four groups
group_names = ['F', 'D', 'C', 'B', 'A']
df['letterGrades'] = pd.cut(df['grade'],
        bins, labels=group_names)
df.head()
Listing 3-32Using Bins

```

为了找到字母等级的平均学习时间，我们将我们的函数应用于 binned 列(列表 [3-33](#Par107) )。

```py
df.groupby('letterGrades')['hours'].mean()
Listing 3-33Applying Function to Newly Created Bin

```

将一个函数应用于一个列看起来像清单 [3-34](#Par109) 。

*   第 1 行:让我们为数据帧中的每个等级获取一个整数值。

```py
# Applying the integer function to the grade column
df['grade'] = df['grade'] = df['grade']
.apply(lambda x: int(x))
df.head()
Listing 3-34Applying a Function to a Column

```

对一个组应用一个函数可以在清单 [3-35](#Par112) 中看到。

*   第 1 行:创建一个分组对象。换句话说，创建一个表示特定分组的对象。在这种情况下，我们按性别对成绩进行分组。
*   第 2 行:显示各团考前成绩的平均值。

```py
gender_preScore = df['grade'].groupby(df['gender'])
gender_preScore.mean()
Listing 3-35Applying a Function to a Group

```

#### 轮到你了

导入`datasets/gradedata.csv`文件并创建一个新的`'status'`入库列，作为通过(> 70)或失败(< =70)。然后，用`passing`的`'status'`计算女学生的平均锻炼时间。

### 对数据行进行排序

查找具有最大值或最小值的行相对容易，但有时您希望为特定列查找具有 50 个最大值或 100 个最小值的行。这就是你需要排名的时候(列表 [3-36](#Par117) )。

```py
import pandas as pd
Location = "datasets/gradedata.csv"
df = pd.read_csv(Location)
df.head()
Listing 3-36Load Data from CSV

```

如果我们想找到分数最低的行，我们需要按分数升序排列所有行。清单 [3-37](#Par119) 显示了创建一个新列的代码，该列是 grade 值按升序排列的等级。

```py
df['graderanked'] = df['grade'].rank(ascending=1)
df.tail()
Listing 3-37Create Column with Ranking by Grade

```

因此，如果我们只想查看分数最低的 20 名学生，我们将使用清单 [3-38](#Par121) 中的代码。

```py
df[df['graderanked'] < 21]
Listing 3-38Bottom 20 Students

```

为了按顺序查看它们，我们需要使用清单 [3-39](#Par123) 中的代码。

```py
df[df['graderanked'] < 6].sort_values('graderanked')
Listing 3-39Bottom 6 Students in Order

```

#### 轮到你了

你能找到每周学习时间最多的 50 名学生吗？

### 基于条件创建列

有时，您需要根据一列或多列中的值对一行数据进行分类，例如根据分数是高于还是低于 70 来确定那些通过或未通过的学生。在本节中，我们将学习如何做到这一点(列出 [3-40](#Par126) )。

```py
import pandas as pd
Location = "datasets/gradedata.csv"
df = pd.read_csv(Location)
df.head()
Listing 3-40Load Data from CSV

```

现在，假设我们想要一个指示学生是否不及格的列(清单 [3-41](#Par128) )。

*   第 1 行:我们导入了`numpy`库
*   第 2 行:创建一个名为`df.failing`的新列，如果`df.grade`小于 70，则该列的值为 yes，否则为 no。

```py
import numpy as np
df['isFailing'] = np.where(df['grade']<70,
'yes', 'no')
df.tail(10)
Listing 3-41Create Yes/No isFailing Column

```

相反，如果我们需要一个列来显示哪些男生分数不及格，我们可以使用清单 [3-42](#Par132) 中的代码。

```py
df['isFailingMale'] = np.where((df['grade']<70)
        & (df['gender'] == 'male'),'yes', 'no')
df.tail(10)
Listing 3-42Create Yes/No isFailingMale Column

```

#### 轮到你了

如果一个学生每周锻炼超过三个小时，学习超过十七个小时，你能为`timemgmt`创建一个显示`busy`的列吗？

### 使用函数创建新列

我过去使用 Excel 做的大部分事情(也是我现在使用 Python 做的事情)是基于现有列创建新列。因此，使用下面的数据(列表 [3-43](#Par135) ，让我们看看我们将如何做。

```py
import pandas as pd
Location = "datasets/gradedata.csv"
df = pd.read_csv(Location)
df.head()
Listing 3-43Load Data from CSV

```

为了创建一个包含每个学生全名的列，我们首先创建一个函数，从两个字符串中创建一个字符串(清单 [3-44](#Par137) )。

```py
def singlename(fn, ln):
    return fn + " " + ln
Listing 3-44Create Function to Generate Full Name

```

现在，如果你测试这个函数，你会发现它可以很好地将亚当和斯密连接成亚当·斯密。然而，我们也可以将它与列选择器一起使用，使用我们的`fname`和`lname`列创建一个新列(清单 [3-45](#Par139) )。

```py
df['fullname'] = singlename(df['fname'],df['lname'])
Listing 3-45Create Column to Hold the Full Name

```

这段代码创建了一个名为`fullname`的列，它连接了名字和姓氏。

#### 轮到你了

你能创建一个名为`total time`的列，将每周的学习时间和锻炼时间加在一起吗？

### 将字符串类别转换为数字变量

为什么我需要将字符串类别转换为数字变量？许多分析工具不能处理文本，但是如果你把这些值转换成数字，事情就简单多了(清单 [3-46](#Par143) )。

```py
import pandas as pd
Location = "datasets/gradedata.csv"
df = pd.read_csv(Location)
df.head()
Listing 3-46Load Data from CSV

```

方法 1:转换单个列来保存数字变量(清单 [3-47](#Par145) )。

```py
def score_to_numeric(x):
    if x=='female':
        return 1
    if x=='male':
        return 0
Listing 3-47Function to Convert Gender to Number

```

现在，在您的列上运行该方法(清单 [3-48](#Par147) )。

```py
df['gender_val'] = df['gender'].apply(score_to_numeric)
df.tail()
Listing 3-48Apply score_to_numeric Function to Gender

```

方法 2:创建单独的布尔列(清单 [3-49](#Par149) )。

```py
df_gender = pd.get_dummies(df['gender'])
df_gender.tail()
Listing 3-49Create Boolean Columns Based on Gender Column

```

将列连接到原始数据集(清单 [3-50](#Par151) )。

```py
# Join the dummy variables to the main dataframe
df_new = pd.concat([df, df_gender], axis=1)
df_new.tail()
# or
# Alterative for joining the new columns
df_new = df.join(df_gender)
df_new.tail()
Listing 3-50Add New Columns to Original Dataframe

```

#### 轮到你了

使用`datasets/gradesdatawithyear.csv`，你能创建一个数字列来用数字 1 到 4 替换新生到高年级的状态吗？

## 组织数据

出于两个原因，原始变量和新创建的变量都需要正确格式化。

首先，我们的分析工具可以正确地与它们一起工作。未能正确格式化缺失值代码或虚拟变量将对您的数据分析产生重大影响。

第二，如果您不必一直查找 Q156 是哪个变量，那么运行分析和解释结果会快得多。

例子包括如下:

*   删除不需要的列
*   更改列名
*   将列名改为小写
*   将日期变量格式化为日期，等等。

### 删除和添加列

有时候我们需要调整数据。要么是遗漏了本应包含的内容，要么是遗漏了本应删除的内容。所以，让我们从清单 [3-51](#Par162) 中的数据集开始。

```py
import pandas as pd
names = ['Bob','Jessica','Mary','John','Mel']
grades = [76,95,77,78,99]
bsdegrees = [1,1,0,0,1]
msdegrees = [2,1,0,0,0]
phddegrees = [0,1,0,0,0]
GradeList = zip(names,grades,bsdegrees,msdegrees,
        phddegrees)
columns=['Names','Grades','BS','MS','PhD']
df = pd.DataFrame(data = GradeList, columns=columns)
df
Listing 3-51Creating Starting Dataset

```

我们可以通过简单地添加清单 [3-52](#Par164) 中的代码来删除一列。

```py
df.drop('PhD', axis=1)
Listing 3-52Dropping a Column

```

用`axis=1`告诉`drop`我们想要删除一列(1)而不是一行(0)。

我们可以通过将新的列名设置为等于 0 来添加一个用零填充的列(清单 [3-53](#Par167) )。

```py
df['HighSchool']=0
Listing 3-53Creating a New Column Filled with Zeros

```

但是，如果您想将新列设置为等于空值，您也可以这样做(清单 [3-54](#Par169) )。

```py
df['PreSchool'] = np.nan
Listing 3-54Creating a New Column Filled with Null Values

```

现在，添加带有值的列并不困难。我们创建一个系列，并将列设置为等于该系列(清单 [3-55](#Par171) )。

```py
d = ([0,1,0,1,0])
s = pd.Series(d, index= df.index)
df['DriversLicense'] = s
df
Listing 3-55Creating a New Column Filled with Values

```

#### 轮到你了

你能删除`bs`、`ms`和`phd`学位栏吗？

可以加一个`Hogwarts Magic Degree`栏吗？除了杰西卡，每个人都有一个；这会让事情变得更难吗？没有吗？那我下次一定要难倒你。

### 选择列

您需要偶尔对数据进行部分选择，尤其是当数据集包含大量列时。在这里，我们学习如何创建一个只包含一些列的 dataframe(清单 [3-56](#Par175) )。

```py
import pandas as pd
Location = "datasets/gradedata.csv"
df = pd.read_csv(Location)
df.head()
Listing 3-56Load Data from CSV

```

现在，为了选择一列数据，我们指定列名(清单 [3-57](#Par177) )。

```py
df['fname']
Listing 3-57Selecting a Column into a List

```

但是，如果您运行该代码，您只能获得列中的数据(注意，标题丢失了)。这是因为它不返回 dataframe 它返回一个列表。为了在选择列时返回 dataframe，我们需要指定它(清单 [3-58](#Par179) )。

```py
df[['fname']]
Listing 3-58Selecting a Column into a Dataframe

```

为了返回多列，我们使用清单 [3-59](#Par181) 中的代码。

```py
df[['fname','age','grade']]
Listing 3-59Selecting Multiple Columns into a Dataframe

```

当然，如果我们想要创建一个包含该列子集的 dataframe，我们可以将它复制到另一个变量中(清单 [3-60](#Par183) )。

```py
df2 = df[['fname','age','grade']]
df2.head()
Listing 3-60Creating New Dataframe from Your Selection

```

#### 轮到你了

我们需要创建一个邮件列表。能否通过选择名字、姓氏和地址字段来创建新的数据帧？

### 更改列名

有时你需要改变你的专栏的名字。有了`pandas`，很容易做到。首先，你加载你的数据(列表 [3-61](#Par186) )。

```py
import pandas as pd

Location = "datasets/gradedata.csv"
df = pd.read_csv(Location)
df.head()

Listing 3-61Load Dataset from CSV

```

但是，当我们查看标题时，我们并不热衷于列名——或者说它没有任何列名。

更改列标题很简单(清单 [3-62](#Par189) )。

```py
df.columns = ['FirstName', 'LastName', 'Gender',
        'Age', 'HoursExercisePerWeek',
        'HoursStudyPerWeek', 'LetterGrade',
        'StreetAddress']
df.head()
Listing 3-62Change All Headers

```

或者，如果您只想更改一两个值，您可以加载标题列表(清单 [3-63](#Par32) )。

```py
headers = list(df.columns.values)
Listing 3-63Load List of Headers into a Temp Variable

```

一旦头被加载，你可以改变一些(清单 [3-64](#Par193) )。

```py
headers[0] = 'FName'
headers[1] = 'LName'
df.columns = headers
df.head()
Listing 3-64Changing Headers

```

#### 轮到你了

能不能把`age`列名改成`years`？

### 将列名设置为小写

这可能不是世界上最大的问题，但是有时我需要将所有的列名转换成小写(或者大写)。本课将讲述如何做到这一点(列表 [3-65](#Par196) )。

```py
import pandas as pd
Location = "datasets/gradedata.csv"
df = pd.read_csv(Location)
df.head()
Listing 3-65Load Data from CSV

```

一旦有了数据，有两种快速的方法将所有的列标题转换成小写(清单 [3-66](#Par198) )。

```py
# method 1
df.columns = map(str.lower, df.columns)
# method 2
df.columns = [x.lower() for x in df.columns]
Listing 3-66Casting All Headers to Lowercase

```

#### 轮到你了

你能想出如何让所有的列标题都大写吗？

### 查找匹配行

当然，您并不总是希望使用整个数据集进行计算。有时您希望只处理数据的子集。在这一课中，我们找出如何做到这一点(清单 [3-67](#Par201) )。

```py
import pandas as pd
names = ['Bob','Jessica','Mary','John','Mel']
grades = [76,95,77,78,99]
GradeList = zip(names,grades)
df = pd.DataFrame(data = GradeList,
        columns=['Names', 'Grades'])
df
Listing 3-67Creating Dataset

```

要查找包含单词 Mel 的所有行，请在新的单元格中使用清单 [3-68](#Par203) 中所示的代码。

```py
df['Names'].str.contains('Mel')
Listing 3-68Filtering Rows

```

在执行完 Python 的这一行之后，您将看到一个布尔值列表——对于与我们的查询匹配的行为 True，对于不匹配的行为 False。

我们可以通过添加`.any`使我们的答案更简短。如果有任何一行匹配，这将只显示一个 True，如果没有一行匹配，则显示 False(清单 [3-69](#Par206) )。

```py
# check if any row matches
df['Names'].str.contains('Mel').any()
Listing 3-69Check if Any Rows Match

```

或者，可以加上`.all`。如果所有行都匹配，这将只显示一个 True，如果至少有一行不匹配，则显示 False(列表 [3-70](#Par208) )。

```py
# check if all rows match
df['Names'].str.contains('Mel').all()
Listing 3-70Check if All Rows Match

```

我们也可以将它与`.loc` (locate)函数一起使用，只显示符合特定标准的行(清单 [3-71](#Par210) )。

```py
# Find the rows that match a criteria like this
df.loc[df['Names'].str.contains('Mel')==True]
# or even like this...
df.loc[df['Grades']==0]
Listing 3-71Show the Rows that Match

```

#### 轮到你了

你能在下面的数据(列表 [3-72](#Par212) )中找到所有至少有一个 MS 学位的人吗？

```py
import pandas as pd
names = ['Bob','Jessi','Mary','John','Mel','Sam',
        'Cathy','Hank','Lloyd']
grades = [76,95,77,78,99,84,79,100,73]
bsdegrees = [1,1,0,0,1,1,1,0,1]
msdegrees = [2,1,0,0,0,1,1,0,0]
phddegrees = [0,1,0,0,0,2,1,0,0]
GradeList = zip(names,grades,bsdegrees,msdegrees,
        phddegrees)
df = pd.DataFrame(data = GradeList, columns=['Name','Grade','BS','MS','PhD'])
df
Listing 3-72Starting Dataset

```

### 根据条件筛选行

```py
import pandas as pd
Location = "datasets/gradedata.csv"
df = pd.read_csv(Location)
df.head()
Listing 3-73Load Data from CSV

```

我们可以显示一列数据(列表 [3-74](#Par215) )。

```py
df['grade'].head()
Listing 3-74One Column

```

或者我们可以显示两列数据(清单 [3-75](#Par217) )。

```py
df[['age','grade']].head()
Listing 3-75Two Columns

```

或者我们可以显示前两行数据(清单 [3-76](#Par219) )。

```py
df[:2]
Listing 3-76First Two Rows

```

要显示等级大于 80 的所有行，请使用清单 [3-77](#Par221) 中的代码。

```py
df[df['grade'] > 80]
Listing 3-77All Rows with Grade > 80

```

使用多个条件有点棘手。因此，如果我们想要得到所有得分高于 99.9 且为男性的学生的列表，我们需要使用清单 [3-78](#Par223) 中所示的代码。

```py
df.ix[(df['grade'] > 99.9) &
    (df['gender'] == 'male') ]
Listing 3-78All Rows Where Men Scored > 99.9

```

相反，如果我们想要所有得分高于 99 的学生或者是女生，我们将需要使用清单 [3-79](#Par225) 中的代码。

```py
df.ix[(df['grade'] > 99) | (df['gender'] == 'female') ]
Listing 3-79All Rows Where Women or Scored > 99

```

#### 轮到你了

你能显示学生是男性，每周锻炼少于两小时，每周学习超过十五小时的所有行吗？

### 基于条件选择行

```py
import pandas as pd
Location = "datasets/gradedata.csv"
df = pd.read_csv(Location)
df.head()
Listing 3-80Load Data from CSV

```

*   第 1 行:如果性别是女性，我们用 TRUE 创建一个变量。
*   第 2 行:如果 grade 大于或等于 90，我们创建一个 TRUE 变量。
*   第 3 行:这是我们选择所有性别均为女性且分数大于或等于 90 的案例的地方。

```py
female = df['gender'] == "female"
a_student = df['grade'] >= 90
df[female & a_student].head()
Listing 3-81Method 1: Using Variables to Hold Attributes

```

```py
df[df['fname'].notnull() & (df['gender'] == "male")]
Listing 3-82Method 2: Using Variable Attributes Directly

```

在清单 [3-82](#Par232) 中，我们选择名字不缺失且性别为男性的所有情况。

#### 轮到你了

你能找到学生每周锻炼四个小时或更多，学习十七个小时或更多，但成绩仍低于 80 分的所有行吗？

### 随机抽样数据框架

这个很简单。显然，有时我们有太大的数据集，我们需要取一个子集，所以让我们从一些加载的数据开始(清单 [3-83](#Par236) )。

```py
import pandas as pd
import numpy as np
Location = "datasets/gradedata.csv"
df = pd.read_csv(Location)
df.tail()
Listing 3-83Load Dataset from CSV

```

为了从数据集中随机选择 100 行，我们可以简单地运行清单 [3-84](#Par238) 中所示的代码。

```py
df.take(np.random.permutation(len(df))[:100])
Listing 3-84Random Sample of 100 Rows from Dataframe

```

#### 轮到你了

您能从该数据集中创建一个 500 行的随机样本吗？